{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 6,\n",
       " 'three': 3,\n",
       " 'visions': 1,\n",
       " 'India': 5,\n",
       " '.': 28,\n",
       " 'In': 1,\n",
       " '3000': 1,\n",
       " 'years': 2,\n",
       " 'history': 2,\n",
       " ',': 21,\n",
       " 'people': 1,\n",
       " 'world': 4,\n",
       " 'come': 1,\n",
       " 'invaded': 1,\n",
       " 'us': 4,\n",
       " 'captured': 1,\n",
       " 'lands': 1,\n",
       " 'conquered': 2,\n",
       " 'minds': 2,\n",
       " 'From': 1,\n",
       " 'Alexander': 1,\n",
       " 'onwards': 1,\n",
       " 'Greeks': 1,\n",
       " 'Turks': 1,\n",
       " 'Moguls': 1,\n",
       " 'Portuguese': 1,\n",
       " 'British': 1,\n",
       " 'French': 1,\n",
       " 'Dutch': 1,\n",
       " 'came': 1,\n",
       " 'looted': 1,\n",
       " 'took': 1,\n",
       " 'Yet': 2,\n",
       " 'done': 1,\n",
       " 'nation': 4,\n",
       " 'We': 5,\n",
       " 'anyone': 1,\n",
       " 'grabbed': 1,\n",
       " 'land': 1,\n",
       " 'culture': 1,\n",
       " 'tried': 1,\n",
       " 'enforce': 1,\n",
       " 'way': 1,\n",
       " 'life': 2,\n",
       " 'Why': 1,\n",
       " '?': 2,\n",
       " 'Because': 2,\n",
       " 'respect': 3,\n",
       " 'freedom': 3,\n",
       " 'others.That': 1,\n",
       " 'first': 2,\n",
       " 'vision': 4,\n",
       " 'believe': 2,\n",
       " 'got': 1,\n",
       " '1857': 1,\n",
       " 'started': 1,\n",
       " 'War': 1,\n",
       " 'Independence': 1,\n",
       " 'It': 2,\n",
       " 'must': 4,\n",
       " 'protect': 1,\n",
       " 'nurture': 1,\n",
       " 'build': 1,\n",
       " 'If': 1,\n",
       " 'free': 1,\n",
       " 'one': 2,\n",
       " 'My': 2,\n",
       " 'second': 1,\n",
       " '’': 2,\n",
       " 'development': 1,\n",
       " 'For': 1,\n",
       " 'fifty': 1,\n",
       " 'developing': 1,\n",
       " 'time': 1,\n",
       " 'see': 3,\n",
       " 'developed': 2,\n",
       " 'among': 1,\n",
       " 'top': 1,\n",
       " '5': 1,\n",
       " 'nations': 1,\n",
       " 'terms': 1,\n",
       " 'GDP': 1,\n",
       " '10': 1,\n",
       " 'percent': 1,\n",
       " 'growth': 1,\n",
       " 'rate': 1,\n",
       " 'areas': 1,\n",
       " 'Our': 2,\n",
       " 'poverty': 1,\n",
       " 'levels': 1,\n",
       " 'falling': 1,\n",
       " 'achievements': 1,\n",
       " 'globally': 1,\n",
       " 'recognised': 1,\n",
       " 'today': 1,\n",
       " 'lack': 1,\n",
       " 'self-confidence': 1,\n",
       " 'self-reliant': 1,\n",
       " 'self-assured': 1,\n",
       " 'Isn': 1,\n",
       " 'incorrect': 1,\n",
       " 'third': 1,\n",
       " 'stand': 1,\n",
       " 'unless': 1,\n",
       " 'stands': 1,\n",
       " 'Only': 1,\n",
       " 'strength': 2,\n",
       " 'respects': 1,\n",
       " 'strong': 1,\n",
       " 'military': 1,\n",
       " 'power': 2,\n",
       " 'also': 1,\n",
       " 'economic': 1,\n",
       " 'Both': 1,\n",
       " 'go': 1,\n",
       " 'hand-in-hand': 1,\n",
       " 'good': 1,\n",
       " 'fortune': 1,\n",
       " 'worked': 2,\n",
       " 'great': 2,\n",
       " 'Dr.': 2,\n",
       " 'Vikram': 1,\n",
       " 'Sarabhai': 1,\n",
       " 'Dept': 1,\n",
       " 'space': 1,\n",
       " 'Professor': 1,\n",
       " 'Satish': 1,\n",
       " 'Dhawan': 1,\n",
       " 'succeeded': 1,\n",
       " 'Brahm': 1,\n",
       " 'Prakash': 1,\n",
       " 'father': 1,\n",
       " 'nuclear': 1,\n",
       " 'material': 1,\n",
       " 'lucky': 1,\n",
       " 'closely': 1,\n",
       " 'consider': 1,\n",
       " 'opportunity': 1,\n",
       " 'four': 1,\n",
       " 'milestones': 1,\n",
       " 'career': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the bag of words\n",
    "word2count = {}\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            if word not in stop_words:\n",
    "                if word not in word2count.keys():\n",
    "                    word2count[word] = 1\n",
    "                else:\n",
    "                    word2count[word] += 1\n",
    "\n",
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# creating the vectors from bag of words\n",
    "import heapq\n",
    "import numpy as np\n",
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)\n",
    "\n",
    "X = []\n",
    "for sentence in sentences:\n",
    "    vector = []\n",
    "    for word in freq_words:\n",
    "        if word in nltk.word_tokenize(sentence):\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)\n",
    "\n",
    "X = np.asarray(X)\n",
    "\n",
    "# print the vectors\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
